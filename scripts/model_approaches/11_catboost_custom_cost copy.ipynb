{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from utils import methods, math_expressions as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/gen_test_v3.csv')\n",
    "test_df = pd.read_csv('../../data/gen_test_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "\n",
    "h = 1 / 15\n",
    "c = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{cases} - 0.0666666666666667 d & \\text{for}\\: d \\leq -0.286980112508514 \\\\\\frac{25}{1 + e^{- 25 d}} & \\text{otherwise} \\end{cases}$"
      ],
      "text/plain": [
       "Piecewise((-0.0666666666666667*d, d <= -0.286980112508514), (25/(1 + exp(-25*d)), True))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{cases} -0.0666666666666667 & \\text{for}\\: d \\leq -0.286980112508514 \\\\\\frac{625 e^{- 25 d}}{\\left(1 + e^{- 25 d}\\right)^{2}} & \\text{otherwise} \\end{cases}$"
      ],
      "text/plain": [
       "Piecewise((-0.0666666666666667, d <= -0.286980112508514), (625*exp(-25*d)/(1 + exp(-25*d))**2, True))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{cases} 0 & \\text{for}\\: d \\leq -0.286980112508514 \\\\- \\frac{15625 e^{- 25 d}}{\\left(1 + e^{- 25 d}\\right)^{2}} + \\frac{31250 e^{- 50 d}}{\\left(1 + e^{- 25 d}\\right)^{3}} & \\text{otherwise} \\end{cases}$"
      ],
      "text/plain": [
       "Piecewise((0, d <= -0.286980112508514), (-15625*exp(-25*d)/(1 + exp(-25*d))**2 + 31250*exp(-50*d)/(1 + exp(-25*d))**3, True))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sympy import diff, symbols, lambdify\n",
    "d = symbols('d')\n",
    "expr = me.cus_cost(h, c, d)\n",
    "expr_grad = diff(expr, d)\n",
    "expr_hess = diff(expr_grad, d)\n",
    "\n",
    "display(expr)\n",
    "display(expr_grad)\n",
    "display(expr_hess)\n",
    "\n",
    "\n",
    "if True:\n",
    "    f = lambdify(d, expr)\n",
    "    f_grad = lambdify(d, expr_grad)\n",
    "    f_hess = lambdify(d, expr_hess)\n",
    "\n",
    "else:\n",
    "    f = lambda x: expr.subs(d, x).evalf(5)\n",
    "    f_grad = lambda x: expr_grad.subs(d, x).evalf(5)\n",
    "    f_hess = lambda x: expr_hess.subs(d, x).evalf(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss:\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "        result = []\n",
    "        for i in range(len(targets)):\n",
    "            actual = targets[i]\n",
    "            predicted = approxes[i]\n",
    "\n",
    "            diff = predicted - actual\n",
    "            \n",
    "            der1 = f_grad(diff)\n",
    "            der2 = f_hess(diff)\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[i]\n",
    "                der2 *= weights[i]\n",
    "            result.append((der1, der2))\n",
    "        return result\n",
    "    \n",
    "class CustomMetric(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error / (weight + 1e-38)\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "\n",
    "            actual = target[i]\n",
    "            predicted = approx[i]\n",
    "\n",
    "            diff = predicted - actual\n",
    "            error = f(diff)\n",
    "            \n",
    "\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            error_sum += w * error\n",
    "\n",
    "        return error_sum, weight_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    X_train = train_df[['N', 'n', 'mean_n', 'std_n', 'alpha_hat', 'beta_hat', 'u_star_hat']]\n",
    "    y_train = train_df['u']\n",
    "\n",
    "    X_test = test_df[['N', 'n', 'mean_n', 'std_n', 'alpha_hat', 'beta_hat', 'u_star_hat']]\n",
    "    y_test = test_df['u']\n",
    "\n",
    "else:\n",
    "    X = train_df[['N', 'n', 'mean_n', 'std_n', 'alpha_hat', 'beta_hat', 'u_star_hat']]\n",
    "    y = train_df['u_star']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preetkaria/miniconda3/envs/mlClass/lib/python3.12/site-packages/catboost/core.py:2311: UserWarning: Failed to import numba for optimizing custom metrics and objectives\n",
      "  _check_train_params(params)\n",
      "<lambdifygenerated-7>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return select([less_equal(d, -0.286980112508514),True], [-0.0666666666666667,625*exp(-25*d)/(1 + exp(-25*d))**2], default=nan)\n",
      "<lambdifygenerated-7>:2: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return select([less_equal(d, -0.286980112508514),True], [-0.0666666666666667,625*exp(-25*d)/(1 + exp(-25*d))**2], default=nan)\n",
      "<lambdifygenerated-7>:2: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  return select([less_equal(d, -0.286980112508514),True], [-0.0666666666666667,625*exp(-25*d)/(1 + exp(-25*d))**2], default=nan)\n",
      "<lambdifygenerated-7>:2: RuntimeWarning: overflow encountered in scalar power\n",
      "  return select([less_equal(d, -0.286980112508514),True], [-0.0666666666666667,625*exp(-25*d)/(1 + exp(-25*d))**2], default=nan)\n",
      "<lambdifygenerated-6>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return select([less_equal(d, -0.286980112508514),True], [-0.0666666666666667*d,25/(1 + exp(-25*d))], default=nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 25.1030734\ttotal: 1.25s\tremaining: 20m 44s\n",
      "1:\tlearn: 25.1030289\ttotal: 2.48s\tremaining: 20m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training has stopped (degenerate solution on iteration 2, probably too small l2-regularization, try to increase it)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x16a770a40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss = CustomLoss()\n",
    "custom_metric = CustomMetric()\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    depth=7,\n",
    "    learning_rate=0.01,\n",
    "    eval_metric=custom_metric,\n",
    "    loss_function=custom_loss,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: {'learn': {'CustomMetric': 25.103028878325574}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>11.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_n</td>\n",
       "      <td>17.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std_n</td>\n",
       "      <td>29.4491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpha_hat</td>\n",
       "      <td>25.1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beta_hat</td>\n",
       "      <td>16.8752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u_star_hat</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Importance\n",
       "0           N     11.2213\n",
       "1           n      0.0000\n",
       "2      mean_n     17.2843\n",
       "3       std_n     29.4491\n",
       "4   alpha_hat     25.1702\n",
       "5    beta_hat     16.8752\n",
       "6  u_star_hat      0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Best score: {model.best_score_}')\n",
    "coef_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': np.round(model.get_feature_importance(), 4)})\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Mean cost: 25.10, Actual Median cost: 21.25\n",
      "Optimal Mean cost: 4.36, Optimal Median cost: 3.17\n"
     ]
    }
   ],
   "source": [
    "test_df['predicted_u_star'] = model.predict(X_test)\n",
    "test_df['actual_cost'] = test_df.apply(lambda row: methods.cal_cost(row['c'], row['h'], row['u'], row['predicted_u_star']), axis=1)\n",
    "print(f'Actual Mean cost: {test_df['actual_cost'].mean():.2f}, Actual Median cost: {test_df['actual_cost'].median():.2f}')\n",
    "print(f'Optimal Mean cost: {test_df['optimal_cost'].mean():.2f}, Optimal Median cost: {test_df['optimal_cost'].median():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "      <th>mean_n</th>\n",
       "      <th>std_n</th>\n",
       "      <th>alpha_hat</th>\n",
       "      <th>beta_hat</th>\n",
       "      <th>intervals_str</th>\n",
       "      <th>u</th>\n",
       "      <th>u_star</th>\n",
       "      <th>u_star_hat</th>\n",
       "      <th>z</th>\n",
       "      <th>optimal_cost</th>\n",
       "      <th>actual_cost</th>\n",
       "      <th>predicted_u_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>12.932681</td>\n",
       "      <td>4.299833</td>\n",
       "      <td>9.046363</td>\n",
       "      <td>1.429600</td>\n",
       "      <td>9.873611453932869_12.181558790848907_20.439509...</td>\n",
       "      <td>373.970646</td>\n",
       "      <td>308.401152</td>\n",
       "      <td>330.455982</td>\n",
       "      <td>0.933259</td>\n",
       "      <td>4.371300</td>\n",
       "      <td>24.931287</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>9.336215</td>\n",
       "      <td>3.195497</td>\n",
       "      <td>8.536206</td>\n",
       "      <td>1.093720</td>\n",
       "      <td>8.266907462181138_9.999238032738244_14.2029088...</td>\n",
       "      <td>161.389327</td>\n",
       "      <td>135.114076</td>\n",
       "      <td>121.730806</td>\n",
       "      <td>1.109942</td>\n",
       "      <td>1.751683</td>\n",
       "      <td>10.759200</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>9.326094</td>\n",
       "      <td>4.260114</td>\n",
       "      <td>4.792446</td>\n",
       "      <td>1.945999</td>\n",
       "      <td>9.216064224518064_8.939377602897661_6.74126765...</td>\n",
       "      <td>143.176863</td>\n",
       "      <td>120.497418</td>\n",
       "      <td>157.110477</td>\n",
       "      <td>0.766960</td>\n",
       "      <td>1.511963</td>\n",
       "      <td>9.545035</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>6.171769</td>\n",
       "      <td>2.741844</td>\n",
       "      <td>5.066802</td>\n",
       "      <td>1.218080</td>\n",
       "      <td>4.268162630400795_5.646163787763241_10.9732434...</td>\n",
       "      <td>108.552055</td>\n",
       "      <td>67.076424</td>\n",
       "      <td>74.632356</td>\n",
       "      <td>0.898758</td>\n",
       "      <td>2.765042</td>\n",
       "      <td>7.236715</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>3.408672</td>\n",
       "      <td>3.727784</td>\n",
       "      <td>0.836121</td>\n",
       "      <td>4.076770</td>\n",
       "      <td>2.7139503189213166_1.8650227067252927_9.985086...</td>\n",
       "      <td>82.809339</td>\n",
       "      <td>68.600863</td>\n",
       "      <td>63.233270</td>\n",
       "      <td>1.084886</td>\n",
       "      <td>0.947232</td>\n",
       "      <td>5.520533</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>3.769411</td>\n",
       "      <td>2.560751</td>\n",
       "      <td>2.166767</td>\n",
       "      <td>1.739648</td>\n",
       "      <td>3.11735382807551_1.9783134491147916_0.91413133...</td>\n",
       "      <td>87.637870</td>\n",
       "      <td>64.876472</td>\n",
       "      <td>50.806139</td>\n",
       "      <td>1.276942</td>\n",
       "      <td>1.517427</td>\n",
       "      <td>5.842435</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9.931571</td>\n",
       "      <td>2.022021</td>\n",
       "      <td>24.124854</td>\n",
       "      <td>0.411674</td>\n",
       "      <td>10.139845582668807_13.268196488069144_8.596625...</td>\n",
       "      <td>106.970370</td>\n",
       "      <td>78.709432</td>\n",
       "      <td>130.343916</td>\n",
       "      <td>0.603860</td>\n",
       "      <td>1.884062</td>\n",
       "      <td>7.131269</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>7.128026</td>\n",
       "      <td>5.330372</td>\n",
       "      <td>1.788231</td>\n",
       "      <td>3.986078</td>\n",
       "      <td>3.956626898229583_1.8282626746323363_13.739765...</td>\n",
       "      <td>334.042238</td>\n",
       "      <td>268.574966</td>\n",
       "      <td>200.318648</td>\n",
       "      <td>1.340739</td>\n",
       "      <td>4.364485</td>\n",
       "      <td>22.269393</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>18.323201</td>\n",
       "      <td>6.923162</td>\n",
       "      <td>7.004767</td>\n",
       "      <td>2.615819</td>\n",
       "      <td>21.25558763838263_19.034362899181332_8.6877522...</td>\n",
       "      <td>233.670311</td>\n",
       "      <td>190.557184</td>\n",
       "      <td>242.398413</td>\n",
       "      <td>0.786132</td>\n",
       "      <td>2.874208</td>\n",
       "      <td>15.577932</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5.778133</td>\n",
       "      <td>2.196956</td>\n",
       "      <td>6.917228</td>\n",
       "      <td>0.835325</td>\n",
       "      <td>8.134566061803032_6.967224733616182_2.94335748...</td>\n",
       "      <td>53.291864</td>\n",
       "      <td>45.443092</td>\n",
       "      <td>67.092193</td>\n",
       "      <td>0.677323</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>3.552702</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  beta         h   c   N  n     mean_n     std_n  alpha_hat  beta_hat  \\\n",
       "0      5   2.5  0.066667  25  29  5  12.932681  4.299833   9.046363  1.429600   \n",
       "1      7   1.5  0.066667  25  16  5   9.336215  3.195497   8.536206  1.093720   \n",
       "2      7   1.0  0.066667  25  21  5   9.326094  4.260114   4.792446  1.945999   \n",
       "3      3   2.0  0.066667  25  16  5   6.171769  2.741844   5.066802  1.218080   \n",
       "4      3   1.0  0.066667  25  30  5   3.408672  3.727784   0.836121  4.076770   \n",
       "5      3   1.5  0.066667  25  20  5   3.769411  2.560751   2.166767  1.739648   \n",
       "6      3   2.5  0.066667  25  15  5   9.931571  2.022021  24.124854  0.411674   \n",
       "7      3   3.0  0.066667  25  36  5   7.128026  5.330372   1.788231  3.986078   \n",
       "8      5   3.0  0.066667  25  16  5  18.323201  6.923162   7.004767  2.615819   \n",
       "9      3   1.5  0.066667  25  15  5   5.778133  2.196956   6.917228  0.835325   \n",
       "\n",
       "                                       intervals_str           u      u_star  \\\n",
       "0  9.873611453932869_12.181558790848907_20.439509...  373.970646  308.401152   \n",
       "1  8.266907462181138_9.999238032738244_14.2029088...  161.389327  135.114076   \n",
       "2  9.216064224518064_8.939377602897661_6.74126765...  143.176863  120.497418   \n",
       "3  4.268162630400795_5.646163787763241_10.9732434...  108.552055   67.076424   \n",
       "4  2.7139503189213166_1.8650227067252927_9.985086...   82.809339   68.600863   \n",
       "5  3.11735382807551_1.9783134491147916_0.91413133...   87.637870   64.876472   \n",
       "6  10.139845582668807_13.268196488069144_8.596625...  106.970370   78.709432   \n",
       "7  3.956626898229583_1.8282626746323363_13.739765...  334.042238  268.574966   \n",
       "8  21.25558763838263_19.034362899181332_8.6877522...  233.670311  190.557184   \n",
       "9  8.134566061803032_6.967224733616182_2.94335748...   53.291864   45.443092   \n",
       "\n",
       "   u_star_hat         z  optimal_cost  actual_cost  predicted_u_star  \n",
       "0  330.455982  0.933259      4.371300    24.931287          0.001334  \n",
       "1  121.730806  1.109942      1.751683    10.759200          0.001334  \n",
       "2  157.110477  0.766960      1.511963     9.545035          0.001334  \n",
       "3   74.632356  0.898758      2.765042     7.236715          0.001334  \n",
       "4   63.233270  1.084886      0.947232     5.520533          0.001338  \n",
       "5   50.806139  1.276942      1.517427     5.842435          0.001340  \n",
       "6  130.343916  0.603860      1.884062     7.131269          0.001334  \n",
       "7  200.318648  1.340739      4.364485    22.269393          0.001336  \n",
       "8  242.398413  0.786132      2.874208    15.577932          0.001334  \n",
       "9   67.092193  0.677323      0.523251     3.552702          0.001334  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlClass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
